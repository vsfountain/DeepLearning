{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T05:02:23.906798Z",
     "start_time": "2017-10-21T05:02:17.045810Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.data import Dataset, Iterator\n",
    "\n",
    "import glob\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T04:44:33.892859Z",
     "start_time": "2017-10-21T04:44:33.887855Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def save_predictions(filename, y):\n",
    "    \"\"\"np.random.permutation\n",
    "    Dumps y into .npy file\n",
    "    \"\"\"\n",
    "    np.save(filename, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T05:03:36.756205Z",
     "start_time": "2017-10-21T05:03:36.734184Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Auxiliary functions for loading data from a folder and obtaining the labels from the file names\n",
    "\n",
    "def get_label_mapping(label_file):\n",
    "    \"\"\"\n",
    "    Returns mappings of label to index and index to label\n",
    "    The input file has list of labels, each on a separate line.\n",
    "    \"\"\"\n",
    "    with open(label_file, 'r') as f:\n",
    "        id2label = f.readlines()\n",
    "        id2label = [l.strip() for l in id2label]\n",
    "    label2id = {}\n",
    "    count = 0\n",
    "    \n",
    "    for label in id2label:\n",
    "        label2id[label] = count\n",
    "        count += 1\n",
    "        \n",
    "    return id2label, label2id\n",
    "\n",
    "\n",
    "def get_label(filepath, label2id):\n",
    "    \"\"\"\n",
    "    Files are assumed to be labeled as: /path/to/file/999_frog.png\n",
    "    Returns label for a filepath\n",
    "    \"\"\"\n",
    "    tokens = filepath.split('/')\n",
    "    label = tokens[-1].split('_')[1][:-4]\n",
    "    \n",
    "    if label in label2id:\n",
    "        return label2id[label]\n",
    "    else:\n",
    "        sys.exit(\"Invalid label: \" + label)\n",
    "        \n",
    "        \n",
    "def get_labels(files, label2id):\n",
    "    \"\"\"\n",
    "    Returns vector of labels extracted from filenames of all files in folder\n",
    "    :param folder: path to data folder\n",
    "    :param label2id: mapping of text labels to numeric ids. (Eg: automobile -> 0)\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    \n",
    "    for f in files:\n",
    "        y.append(get_label(f,label2id))\n",
    "        \n",
    "    return np.array(y)\n",
    "\n",
    "\n",
    "def input_parser(img_path, label):\n",
    "    one_hot = tf.one_hot(label, num_classes)\n",
    "    img_file = tf.read_file(img_path)\n",
    "    img_decoded = tf.image.decode_image(img_file, channels=3)\n",
    "    \n",
    "    return img_decoded, one_hot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T05:03:38.237027Z",
     "start_time": "2017-10-21T05:03:38.232023Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def load_data(root_folder, data_folder, labels, shuffle=False):\n",
    "    \n",
    "    data_location = root_folder + data_folder\n",
    "    label_map = get_label_mapping(root_folder + labels)[1]\n",
    "    data = [file for file in glob.glob(data_location + '*/*')]\n",
    "    labels = get_labels(data, label_map)\n",
    "    \n",
    "    return data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T05:03:50.540167Z",
     "start_time": "2017-10-21T05:03:50.291286Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cifar10-hw1\\\\train\\\\0_frog.png', 'cifar10-hw1\\\\train\\\\10000_automobile.png', 'cifar10-hw1\\\\train\\\\10001_frog.png', 'cifar10-hw1\\\\train\\\\10002_frog.png', 'cifar10-hw1\\\\train\\\\10003_ship.png', 'cifar10-hw1\\\\train\\\\10004_ship.png', 'cifar10-hw1\\\\train\\\\10005_cat.png', 'cifar10-hw1\\\\train\\\\10006_deer.png', 'cifar10-hw1\\\\train\\\\10007_frog.png', 'cifar10-hw1\\\\train\\\\10008_airplane.png'] [6 1 6 6 8 8 3 4 6 0]\n"
     ]
    }
   ],
   "source": [
    "root_folder  = 'cifar10-hw1/'\n",
    "train_folder = 'train'\n",
    "labels = 'labels.txt'\n",
    "\n",
    "data, labels = load_data('cifar10-hw1/', 'train', 'labels.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-21T05:01:46.281673Z",
     "start_time": "2017-10-21T05:01:43.500331Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "    tr_data = tf.contrib.data.Dataset.from_tensor_slices((tf.constant(data),\n",
    "                                                         tf.constant(labels)))\n",
    "    tr_data = tr_data.map(input_parser)\n",
    "    iterator = Iterator.from_structure(tr_data.output_types,\n",
    "                                       tr_data.output_shapes)\n",
    "\n",
    "    next_element = iterator.get_next()\n",
    "    training_init_op = iterator.make_initializer(tr_data)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(training_init_op)\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                elem = sess.run(next_element)\n",
    "\n",
    "            except tf.errors.OutOfRangeError:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T07:26:32.767190Z",
     "start_time": "2017-10-20T07:26:32.761184Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T07:30:36.641435Z",
     "start_time": "2017-10-20T07:30:36.612407Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def part1_model(features, labels, mode):\n",
    "    input_layer = tf.reshape(features['x'], [-1, 32, 32, 3])\n",
    "    conv1 = tf.layers.conv2d(inputs=input_layer,\n",
    "                                 filters=32,\n",
    "                                 kernel_size=[5, 5],\n",
    "                                 padding='same',\n",
    "                                 activation=tf.nn.relu)\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1,\n",
    "                                   pool_size=[2, 2],\n",
    "                                   strides=2)\n",
    "    \n",
    "    conv2 = tf.layers.conv2d(inputs=pool1,\n",
    "                            filters=64,\n",
    "                            kernel_size=[5, 5],\n",
    "                            padding='same',\n",
    "                            activation=tf.nn.relu)\n",
    "    \n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2,\n",
    "                                   pool_size=[2, 2],\n",
    "                                   strides=2)\n",
    "    \n",
    "    pool2_flat = tf.reshape(pool2, [-1, 8*8*64])\n",
    "    \n",
    "    dense = tf.layers.dense(input=pool2,\n",
    "                            units=1024,\n",
    "                            activation=tf.nn.relu)\n",
    "    \n",
    "    output_layer = tf.layers.dense(input=dense, units=10)\n",
    "    \n",
    "    predictions = {'classes': tf.argmax(input=output_layer, axis=1),\n",
    "                   'prob': tf.nn.softmax(output_layer, name='softmax')}\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "    \n",
    "    OH_labels = tf.one_hot(indices=tf.cast(labels, tf.int32), depth=10)\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=OH_labels,\n",
    "                                           logits=output_layer)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = GradientDescentOptimizer(learning_rate=.0001)\n",
    "        train_op = optimizer.minimize(loss=loss,\n",
    "                                      global_step=tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                          loss=loss,\n",
    "                                          train_op=train_op)\n",
    "    \n",
    "    eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels=labels,\n",
    "                                                       predictions=predictions['classes'])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode=mode,\n",
    "                                      loss=losss,\n",
    "                                      eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T07:33:01.453456Z",
     "start_time": "2017-10-20T07:33:01.446450Z"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    cifar_classify = tf.estimator.Estimator(model_fn=part1_model,\n",
    "                                            model_dir='/tmp/part1')\n",
    "\n",
    "    tensors_log = {'probabilities': 'softmax'}\n",
    "    hook = tf.train.LoggingTensorHook(tensors=tensors_log, every_n_iter=50)\n",
    "\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(x={'x': x_tr},\n",
    "                                                        y=y_tr,\n",
    "                                                        batch_size=100,\n",
    "                                                        num_epochs=None,\n",
    "                                                        shuffle=True)\n",
    "    \n",
    "    cifar_classify.train(input_fn=train_input_fn,\n",
    "                         steps=20000,\n",
    "                         hooks=[hook]\n",
    "                        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-20T07:33:03.736963Z",
     "start_time": "2017-10-20T07:33:03.708938Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_save_checkpoints_secs': 600, '_model_dir': '/tmp/part1', '_log_step_count_steps': 100, '_save_checkpoints_steps': None, '_save_summary_steps': 100, '_tf_random_seed': 1}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-9d335f479abd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-47-e4bbb87d7b46>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(unused_argv)\u001b[0m\n\u001b[0;32m     14\u001b[0m     cifar_classify.train(input_fn=train_input_fn,\n\u001b[0;32m     15\u001b[0m                          \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                          \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhook\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                         )\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps)\u001b[0m\n\u001b[0;32m    239\u001b[0m       \u001b[0mhooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStopAtStepHook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks)\u001b[0m\n\u001b[0;32m    626\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_and_assert_global_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m       features, labels = self._get_features_and_labels_from_input_fn(\n\u001b[1;32m--> 628\u001b[1;33m           input_fn, model_fn_lib.ModeKeys.TRAIN)\n\u001b[0m\u001b[0;32m    629\u001b[0m       estimator_spec = self._call_model_fn(features, labels,\n\u001b[0;32m    630\u001b[0m                                            model_fn_lib.ModeKeys.TRAIN)\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_get_features_and_labels_from_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_input_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    583\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'config'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\numpy_io.py\u001b[0m in \u001b[0;36minput_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m    107\u001b[0m       \u001b[0mordered_dict_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_target_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordered_dict_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m       shape_dict_of_x = {k: ordered_dict_x[k].shape\n\u001b[0;32m    111\u001b[0m                          for k in ordered_dict_x.keys()}\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\estimator\\inputs\\numpy_io.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    107\u001b[0m       \u001b[0mordered_dict_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0munique_target_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mordered_dict_x\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m       shape_dict_of_x = {k: ordered_dict_x[k].shape\n\u001b[0;32m    111\u001b[0m                          for k in ordered_dict_x.keys()}\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "main(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
